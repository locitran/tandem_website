{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ccbdcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loci/miniconda3/envs/tandem/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15928eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PurePosixPath('/home/loci/tandem_website'),\n",
       " '/home/loci/tandem_website/gradio_app/tmp')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "import ipynbname\n",
    "import gradio as gr\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "root = ipynbname.path().parents[1]\n",
    "sys.path.insert(0, str(root))\n",
    "# from tandem.src.utils.logger import LOGGER\n",
    "\n",
    "from src.logger import LOGGER\n",
    "\n",
    "# tandem folder\n",
    "tandem_folder = os.path.join(root, 'tandem')\n",
    "sys.path.append(tandem_folder)\n",
    "\n",
    "tmp_folder = os.path.join(root, 'gradio_app/tmp')\n",
    "\n",
    "# jobs_folder = '/mnt/nas_1/YangLab/project/tandem_website/tandem/jobs'\n",
    "jobs_folder = os.path.join(root, 'tandem/jobs')\n",
    "figure_1 = os.path.join(root, 'gradio_app/images/figure_1.jpg')\n",
    "cssfile = os.path.join(root, 'gradio_app/css/font.css')\n",
    "\n",
    "css_interface = os.path.join(root, 'gradio_app/css/interface.css')\n",
    "custom_css = ''\n",
    "with open(css_interface, \"r\") as f:\n",
    "    custom_css += f.read() + '\\n'\n",
    "with open(cssfile, \"r\") as f:\n",
    "    custom_css += f.read() + '\\n'\n",
    "\n",
    "# from src.col_test import collections\n",
    "root, tmp_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba232879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5.38.0', '/home/loci/tandem_website/gradio_app')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.__version__, os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132fa9d7",
   "metadata": {},
   "source": [
    "# MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b2742e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertOneResult(ObjectId('6958f1337f0a10bdbf5e36ad'), acknowledged=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient()\n",
    "db = client[\"job_db\"]\n",
    "collections = db[\"input_queue\"]\n",
    "\n",
    "# Session A has 3 jobs\n",
    "job_001 = {\n",
    "    \"status\": \"finished\",\n",
    "    \"session_id\": \"loci\",\n",
    "    \"mode\": \"Inferencing\",\n",
    "    \"inf_sav_txt\": \"P29033 Y217D\",\n",
    "    \"inf_sav_btn\": \"Uploadasdasdasdasdasdasdasd\",\n",
    "    \"model_dropdown\": \"TANDEM\",\n",
    "    \"tf_sav_txt\": \"\",\n",
    "    \"tf_sav_btn\": \"Upload\",\n",
    "    \"str_txt\": \"\",\n",
    "    \"str_btn\": \"Upload\",\n",
    "    \"job_name\": \"Tue_Dec_9_13-28-04_2025\",\n",
    "    \"email\": \"\"\n",
    "}\n",
    "\n",
    "job_002 = {\n",
    "    \"status\": \"finished\",\n",
    "    \"session_id\": \"loci\",\n",
    "    \"mode\": \"Inferencing\",\n",
    "    \"inf_sav_txt\": \"P29033 Y217D\",\n",
    "    \"inf_sav_btn\": \"Upload\",\n",
    "    \"model_dropdown\": \"TANDEM\",\n",
    "    \"tf_sav_txt\": \"\",\n",
    "    \"tf_sav_btn\": \"Upload\",\n",
    "    \"str_txt\": \"\",\n",
    "    \"str_btn\": \"Upload\",\n",
    "    \"job_name\": \"Tue_Dec_9_13-55-29_2025\",\n",
    "    \"email\": \"\"\n",
    "}\n",
    "\n",
    "job_003 = {\n",
    "    \"status\": \"finished\",\n",
    "    \"session_id\": \"abc\",\n",
    "    \"mode\": \"Inferencing\",\n",
    "    \"inf_sav_txt\": \"P29033 Y217D\",\n",
    "    \"inf_sav_btn\": \"Upload\",\n",
    "    \"model_dropdown\": \"TANDEM\",\n",
    "    \"tf_sav_txt\": \"\",\n",
    "    \"tf_sav_btn\": \"Upload\",\n",
    "    \"str_txt\": \"\",\n",
    "    \"str_btn\": \"Upload\",\n",
    "    \"job_name\": \"2025-12-15_14-58-07\",\n",
    "    \"email\": \"\"\n",
    "}\n",
    "\n",
    "job_004 = {\n",
    "    \"status\": \"finished\",\n",
    "    \"session_id\": \"abc\",\n",
    "    \"mode\": \"Transfer learning\",\n",
    "    \"inf_sav_txt\": \"P29033 Y217D\",\n",
    "    \"inf_sav_btn\": \"Upload\",\n",
    "    \"model_dropdown\": \"TANDEM\",\n",
    "    \"tf_sav_txt\": \"\",\n",
    "    \"tf_sav_btn\": \"Upload\",\n",
    "    \"str_txt\": \"\",\n",
    "    \"str_btn\": \"Upload\",\n",
    "    \"job_name\": \"2025-12-15_14-58-07\",\n",
    "    \"email\": \"\"\n",
    "}\n",
    "\n",
    "# Session B has 2 jobs\n",
    "job_101 = {\n",
    "    \"status\": \"finished\",\n",
    "    \"session_id\": \"abc\",\n",
    "    \"mode\": \"Inferencing\",\n",
    "    \"inf_sav_txt\": \"P29033 Y217D\",\n",
    "    \"inf_sav_btn\": \"Upload\",\n",
    "    \"model_dropdown\": \"TANDEM\",\n",
    "    \"tf_sav_txt\": \"\",\n",
    "    \"tf_sav_btn\": \"Upload\",\n",
    "    \"str_txt\": \"\",\n",
    "    \"str_btn\": \"Upload\",\n",
    "    \"job_name\": \"2025-12-15_15-03-01\",\n",
    "    \"email\": \"\"\n",
    "}\n",
    "\n",
    "job_102 = {\n",
    "    \"status\": \"finished\",\n",
    "    \"session_id\": \"abc\",\n",
    "    \"mode\": \"Inferencing\",\n",
    "    \"inf_sav_txt\": \"P29033 Y217D\",\n",
    "    \"inf_sav_btn\": \"Upload\",\n",
    "    \"model_dropdown\": \"TANDEM\",\n",
    "    \"tf_sav_txt\": \"\",\n",
    "    \"tf_sav_btn\": \"Upload\",\n",
    "    \"str_txt\": \"\",\n",
    "    \"str_btn\": \"Upload\",\n",
    "    \"job_name\": \"2025-12-15_14-52-21\",\n",
    "    \"email\": \"\"\n",
    "}\n",
    "\n",
    "collections.insert_one(job_001)\n",
    "collections.insert_one(job_002)\n",
    "collections.insert_one(job_003)\n",
    "collections.insert_one(job_004)\n",
    "collections.insert_one(job_101)\n",
    "collections.insert_one(job_102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "140ff78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tandem.src.main import run "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ca607",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2cab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%blocks --share\n",
    "import gradio as gr\n",
    "\n",
    "def on_submit(text):\n",
    "    return (\n",
    "        f\"You typed: {text}\",\n",
    "        gr.update(visible=False)\n",
    "    )\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Textbox Test\")\n",
    "\n",
    "    with gr.Group() as g:\n",
    "        textbox = gr.Textbox(\n",
    "            label=\"Enter something\",\n",
    "            placeholder=\"Type here and press Enter\",\n",
    "        )\n",
    "        output = gr.Markdown()\n",
    "\n",
    "    textbox.submit(\n",
    "        fn=on_submit,\n",
    "        inputs=textbox,\n",
    "        outputs=[output, g],\n",
    "    )\n",
    "\n",
    "demo.launch(server_port=7890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1dd60d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7890\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7890/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def on_upload(file):\n",
    "    return (\n",
    "        gr.update(visible=False),  # hide UploadButton\n",
    "        gr.update(value=file, visible=True)    # show File GROUP\n",
    "    )\n",
    "\n",
    "def on_delete(_):\n",
    "    return (\n",
    "        gr.update(visible=True),   # show UploadButton\n",
    "        gr.update(value=None, visible=True)   # hide File GROUP\n",
    "    )\n",
    "\n",
    "file_view = gr.File(file_types=[\".txt\"], visible=True, render=False)\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### Upload ‚Üí hide ‚Üí delete ‚Üí restore\")\n",
    "\n",
    "    upload_btn = gr.UploadButton(\n",
    "        \"Upload SAVs\",\n",
    "        file_types=[\".txt\"],\n",
    "        visible=True\n",
    "    )\n",
    "\n",
    "    file_view = gr.File(file_types=[\".txt\"], visible=True)\n",
    "\n",
    "    upload_btn.upload(\n",
    "        fn=on_upload,\n",
    "        inputs=upload_btn,\n",
    "        outputs=[upload_btn, file_view]\n",
    "    )\n",
    "\n",
    "    file_view.delete(\n",
    "        fn=on_delete,\n",
    "        inputs=file_view,\n",
    "        outputs=[upload_btn, file_view]\n",
    "    )\n",
    "\n",
    "demo.launch(server_port=7890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4304d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7890\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0053581",
   "metadata": {},
   "source": [
    "# Run the gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c2940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pprint import pformat\n",
    "from datetime import datetime\n",
    "import json \n",
    "import pandas as pd \n",
    "import gradio as gr\n",
    "import os \n",
    "import secrets\n",
    "import gradio as gr\n",
    "import string\n",
    "from tandem.src.main import run \n",
    "import time\n",
    "from src.update_session import generate_token\n",
    "from src.update_input import upload_file, on_delete_file\n",
    "from src.web_interface import query_structure, on_mode, time_zone\n",
    "from src.update_input import handle_SAV,handle_STR\n",
    "from src.update_output import multindex_DataFrame, zip_folder\n",
    "import shutil\n",
    "from yattag import Doc\n",
    "\n",
    "def on_session(_session_id, _param_state):\n",
    "    \"\"\"\n",
    "    1. Start session by generating new id or providing old id\n",
    "    2. Update parameter state (status and session_id)\n",
    "    3. Update dropdown of pre-trained models to include trained models from user\n",
    "        Look up all jobs of session_id to find inference jobs which were finished.\n",
    "\n",
    "    If id is not valid, no session id is recorded\n",
    "    \"\"\"\n",
    "    old_session_ids = collections.distinct(\"session_id\")\n",
    "    _session_id = _session_id.strip()\n",
    "    param_udt = _param_state.copy()\n",
    "    param_udt['status'] = None\n",
    "    param_udt[\"session_id\"] = None\n",
    "    job_dropdown_upt = gr.update(visible=False)\n",
    "    model_dropdown_udt = gr.update()\n",
    "    model_choices = [\"TANDEM\", \"TANDEM-DIMPLE for GJB2\", \"TANDEM-DIMPLE for RYR1\"]\n",
    "\n",
    "    # Case 1: Empty input ‚Üí Generate a new unique session ID\n",
    "    if not _session_id:\n",
    "        # loop until finding an unused ID (guaranteed uniqueness)\n",
    "        while True:\n",
    "            new_id = generate_token(length=4) \n",
    "            # if new_id overlap with old one --> redo\n",
    "            if new_id not in old_session_ids:\n",
    "                session_id_udt = gr.update(value=new_id, label=f\"Session {new_id} in use\")\n",
    "                session_status_udt = f\"üîÑ New session ID has been generated. <br>‚ÑπÔ∏è Please save the session ID for future reference.\"\n",
    "                param_udt[\"session_id\"] = new_id\n",
    "                break\n",
    "    # Case 2: User-provided input, check validity\n",
    "    elif _session_id not in old_session_ids:\n",
    "        session_id_udt = gr.update(value=\"\", label=f\"‚ùå Session {_session_id} not found\")\n",
    "        session_status_udt = f\"Please generate or paste a valid one.\"\n",
    "    # Case 3: Valid existing session\n",
    "    else:\n",
    "        session_id_udt = gr.update(value=_session_id, label=f\"Session {_session_id} in use\")\n",
    "        session_status_udt = f\"‚úÖ Session resumed.\"\n",
    "\n",
    "        # List out existing jobs of this _session_id and status not None\n",
    "        existing_jobs = collections.distinct(\n",
    "            \"job_name\",\n",
    "            {\n",
    "                \"session_id\": _session_id, \n",
    "                \"status\": {\"$in\": [\"pending\", \"processing\", \"finished\"]}\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if len(existing_jobs) == 0:\n",
    "            job_dropdown_upt = gr.update(visible=False, value=None, choices=[], \n",
    "                interactive=False,label=\"No jobs in this session yet\",)\n",
    "        else:\n",
    "            first_job = existing_jobs[0]\n",
    "            param_udt = collections.find_one(\n",
    "                {'session_id': _session_id,'job_name'  : first_job,}, {\"_id\": 0}\n",
    "            )\n",
    "            job_dropdown_upt = gr.update(\n",
    "                visible=True, value=first_job, choices=existing_jobs, interactive=True, label='Old jobs',)\n",
    "\n",
    "            # List out pretrained model saved from job_name, status, and mode \n",
    "            pre_trained_models = collections.distinct(\n",
    "                \"job_name\",\n",
    "                {\n",
    "                    \"session_id\": _session_id, \n",
    "                    \"status\": \"finished\",\n",
    "                    \"mode\": \"Transfer learning\"\n",
    "                }\n",
    "            )\n",
    "            model_choices += pre_trained_models\n",
    "            model_dropdown_udt = gr.update(choices=model_choices)\n",
    "\n",
    "    return session_id_udt, session_status_udt, job_dropdown_upt, param_udt, model_dropdown_udt\n",
    "\n",
    "def update_input_param(\n",
    "    \n",
    "    _mode,\n",
    "    _inf_sav_txt,\n",
    "    _inf_sav_btn,\n",
    "    _model_dropdown,\n",
    "    _tf_sav_txt,\n",
    "    _tf_sav_btn,\n",
    "    _str_txt,\n",
    "    _str_btn,\n",
    "    _job_name_txt,\n",
    "    _email_txt,\n",
    "    _param_state,\n",
    "    _submit_status,\n",
    "):  \n",
    "    _submit_status = (_submit_status or \"\")\n",
    "    params_udt = _param_state.copy()\n",
    "    error_message = \"\"\n",
    "\n",
    "    LOGGER.info(_inf_sav_btn)\n",
    "    LOGGER.info(_tf_sav_btn)\n",
    "\n",
    "    # 1) Pick SAV input (file > text)\n",
    "    if _mode == \"Inferencing\":\n",
    "        SAV_input = _inf_sav_btn if (_inf_sav_btn and os.path.isfile(_inf_sav_btn)) else (_inf_sav_txt or \"\")\n",
    "    elif _mode == \"Transfer Learning\":\n",
    "        SAV_input = _tf_sav_btn if (_tf_sav_btn and os.path.isfile(_tf_sav_btn)) else (_tf_sav_txt or \"\")\n",
    "    else:\n",
    "        raise KeyError(f\"Unknown mode: {_mode}\")\n",
    "\n",
    "    # 2) Validate SAVs\n",
    "    SAV_message, SAV_data = handle_SAV(_mode, SAV_input)\n",
    "    if (SAV_data is not None):\n",
    "        SAV = [f\"{ele['acc']} {ele['wt_resid_mt']}\" for ele in SAV_data]\n",
    "        label = None if _mode == 'Inferencing' else SAV_data['label']\n",
    "        \n",
    "        params_udt['status'] = 'pending'\n",
    "        params_udt['mode'] = _mode\n",
    "        params_udt['SAV'] = SAV\n",
    "        params_udt['label'] = label\n",
    "        params_udt['model'] = _model_dropdown\n",
    "        params_udt['job_name'] = _job_name_txt\n",
    "        params_udt['email'] = _email_txt\n",
    "    else:\n",
    "        params_udt['status'] = None\n",
    "        error_message = SAV_message\n",
    "\n",
    "    # 3) Validate STR\n",
    "    # If user uploaded a file\n",
    "    if _str_btn and os.path.isfile(_str_btn):\n",
    "        # basename of uploaded file\n",
    "        basename = os.path.basename(_str_btn)\n",
    "        tmpfile = os.path.join(tmp_folder, basename)\n",
    "        shutil.copy2(_str_btn, tmpfile)\n",
    "        params_udt['STR'] = tmpfile\n",
    "    # If nothing provided, allow None\n",
    "    elif _str_txt is None or _str_txt.strip() == \"\":\n",
    "        params_udt['STR'] = None\n",
    "    else:\n",
    "        STR_message, STR_input = handle_STR(_str_txt)\n",
    "        if STR_input is None:\n",
    "            params_udt['status'] = None\n",
    "            error_message = STR_message\n",
    "        else:\n",
    "            params_udt['STR'] = STR_input\n",
    "\n",
    "    # status is False meaning that either STR_input or SAV_data are fail\n",
    "    if params_udt['status'] is not None:\n",
    "        input_section_udt  = gr.update(visible=False)   \n",
    "        _submit_status += f\"\\nüì¶ Payload collected for job: {_job_name_txt}\"\n",
    "        _submit_status += f\"\\n{pformat(params_udt, width=200, compact=True)}\"\n",
    "        submit_status_udt = gr.update(value=_submit_status, visible=True)\n",
    "        submit_btn_udt = gr.update(visible=False) # turn off\n",
    "        reset_btn_udt = gr.update(visible=True, interactive=True) # turn on\n",
    "        timer_udt = gr.update(active=True) # turn on\n",
    "    else:\n",
    "        params_udt = _param_state.copy()\n",
    "        input_section_udt  = gr.update(visible=True)   \n",
    "        _submit_status += f\"\\n‚ùå {error_message}\"\n",
    "        submit_status_udt = gr.update(value=_submit_status, visible=True)\n",
    "        submit_btn_udt = gr.update(visible=True, interactive=True) # turn off\n",
    "        reset_btn_udt = gr.update(visible=False) # turn off\n",
    "        timer_udt = gr.update(active=False) # turn on\n",
    "    \n",
    "    LOGGER.info(params_udt)\n",
    "    return params_udt, input_section_udt, submit_status_udt, submit_btn_udt, reset_btn_udt, timer_udt\n",
    "\n",
    "def toSAV_coords(SAVs):\n",
    "    \"\"\"\n",
    "    >>> a = ['P29033 Y217E', 'P29033 Y217F', 'P29033 Y217T']\n",
    "    >>> toSAV_coords(a)\n",
    "    ['P29033 217 Y E', 'P29033 217 Y F', 'P29033 217 Y T']\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for s in SAVs:\n",
    "        acc, wt_resid_mt = s.split()\n",
    "        wt = wt_resid_mt[0]\n",
    "        mt = wt_resid_mt[-1]\n",
    "        resid = wt_resid_mt[0+1:-1]\n",
    "        out.append(f\"{acc} {resid} {wt} {mt}\")\n",
    "    return out\n",
    "\n",
    "def on_job(_job_dropdown, _param_state, folder):\n",
    "    \"\"\"Switch among existing jobs\n",
    "    Stimulate the effect of dropdown button of job, where it saves old jobs \n",
    "    from a given session id.\n",
    "\n",
    "    on_job event is triggered when user select new job_name (same session id)\n",
    "        - Update and load _param_state (from jobs/session_id/job_name/params.json)\n",
    "        - Check status to decide rendering\n",
    "            + If finished: render submit_section, output_section\n",
    "            + If processing/pending: render submit_section\n",
    "            + No the other way --> Only submitted job has record\n",
    "\n",
    "    New task:\n",
    "        - Remove old job(s)\n",
    "    \"\"\"\n",
    "    \n",
    "    _session_id = _param_state['session_id']\n",
    "    _job_name   = _job_dropdown\n",
    "\n",
    "    param_udt = collections.find_one(\n",
    "        {'session_id': _session_id, 'job_name'  : _job_name}, {\"_id\": 0}\n",
    "    )\n",
    "    if not param_udt:\n",
    "        raise LookupError(\"Cannot find job from on_job function\")\n",
    "\n",
    "    _job_status = param_udt.get('status', None)\n",
    "    job_start = param_udt.get(\"job_start\", None)\n",
    "    job_end   = param_udt.get(\"job_end\", None)\n",
    "\n",
    "    input_section_udt = gr.update(visible=False)   \n",
    "    output_section_udt = gr.update(visible=False)\n",
    "    pred_table_udt   = gr.update(visible=False)\n",
    "\n",
    "    process_status_udt = gr.update(visible=False)\n",
    "    submit_btn_udt     = gr.update(visible=False)\n",
    "    reset_btn_udt      = gr.update(visible=True)\n",
    "    submit_section_udt = gr.update(visible=True)\n",
    "    timer_udt = gr.update(active=True)\n",
    "\n",
    "    if _job_status == 'finished':\n",
    "        output_section_udt = gr.update(visible=True)\n",
    "        pred_file  = os.path.join(folder, _session_id, _job_name, \"predictions.csv\")\n",
    "        df_pred    = pd.read_csv(pred_file)\n",
    "        pred_table_udt   = gr.update(value=df_pred, visible=True)\n",
    "\n",
    "        runtime = int(job_end - job_start)\n",
    "        msg = f\"üì¶ Payload collected for job: {_job_name}\"\n",
    "        msg += f\"\\n{json.dumps(param_udt, indent=2, sort_keys=True)}\"\n",
    "        msg = f\"\\n‚úÖ Finished in {runtime}s\"\n",
    "        submit_status_udt = gr.update(value=msg, visible=True)\n",
    "        process_status_udt = gr.update(visible=False)\n",
    "        timer_udt = gr.update(active=False)\n",
    "\n",
    "    elif _job_status == 'pending':\n",
    "        msg = f\"üì¶ Payload collected for job: {_job_name}\"\n",
    "        msg += f\"\\n{json.dumps(_param_state, indent=2, sort_keys=True)}\"\n",
    "        submit_status_udt  = gr.update(value=msg, visible=True)\n",
    "        process_status_udt = gr.update(value=\"‚è≥ Waiting in queue...\", visible=True)\n",
    "    \n",
    "    elif _job_status == 'processing' and job_start:\n",
    "        msg = f\"üì¶ Payload collected for job: {_job_name}\"\n",
    "        msg += f\"\\n{json.dumps(_param_state, indent=2, sort_keys=True)}\"\n",
    "        submit_status_udt  = gr.update(value=msg, visible=True)\n",
    "\n",
    "        elapsed = int(time.time() - job_start)\n",
    "        emoji_frames = [\"‚è≥\", \"üîÑ\", \"üîÅ\", \"üîÉ\"]\n",
    "        icon = emoji_frames[elapsed % len(emoji_frames)]\n",
    "        process_status_udt = gr.update(value=f\"{icon} Model is running... {elapsed} second{'s' if elapsed != 1 else ''} elapsed.\", visible=True)\n",
    "          \n",
    "    else: # _job_status is None:\n",
    "        input_section_udt  = gr.update(visible=True)   \n",
    "        submit_btn_udt     = gr.update(visible=True)\n",
    "        reset_btn_udt      = gr.update(visible=False) # Unblind submit button\n",
    "        submit_status_udt   = gr.update(visible=False)\n",
    "        timer_udt           = gr.update(active=False)\n",
    "        \n",
    "    return (\n",
    "        input_section_udt,\n",
    "        submit_section_udt,\n",
    "        output_section_udt,\n",
    "        process_status_udt,\n",
    "        pred_table_udt,\n",
    "        submit_status_udt,\n",
    "        submit_btn_udt,\n",
    "        reset_btn_udt,\n",
    "        param_udt,\n",
    "        timer_udt,\n",
    "    )\n",
    "    \n",
    "def send_job(_param_state, jobs_folder):\n",
    "\n",
    "    _job_status = _param_state.get('status', None)\n",
    "\n",
    "    if _job_status != 'pending':\n",
    "        return _param_state\n",
    "\n",
    "    params_udt = _param_state.copy()\n",
    "\n",
    "    session_id = params_udt[\"session_id\"]\n",
    "    job_name   = params_udt[\"job_name\"]\n",
    "\n",
    "    params_udt[\"status\"] = \"processing\"\n",
    "    params_udt[\"job_start\"] = time.time()\n",
    "\n",
    "    # Insert initial record\n",
    "    collections.insert_one(params_udt)\n",
    "\n",
    "    # ---- Run the job (blocking) ----\n",
    "    run(\n",
    "        query=toSAV_coords(params_udt[\"SAV\"]),\n",
    "        labels=params_udt[\"label\"],\n",
    "        custom_PDB=params_udt[\"label\"],\n",
    "        job_name=f\"{session_id}/{job_name}\",\n",
    "    )\n",
    "\n",
    "    # ---- Job finished ----\n",
    "    params_udt[\"status\"] = \"finished\"\n",
    "    params_udt[\"job_end\"] = time.time()\n",
    "\n",
    "    collections.update_one(\n",
    "        {\"session_id\": session_id, \"job_name\": job_name},\n",
    "        {\"$set\": {\n",
    "            \"status\": \"finished\",\n",
    "            \"job_end\": params_udt[\"job_end\"]\n",
    "        }}\n",
    "    )\n",
    "    params_to_dump = dict(params_udt)   # copy\n",
    "    params_to_dump.pop(\"_id\", None)     # üîë remove ObjectId\n",
    "\n",
    "    with open(f\"{jobs_folder}/{session_id}/{job_name}/params.json\", \"w\") as f:\n",
    "        json.dump(params_to_dump, f, indent=4)\n",
    "\n",
    "    return params_udt\n",
    "\n",
    "def on_reset(_param_state):\n",
    "    \"\"\"\n",
    "    Render input_section, submit_section, Hide result_section\n",
    "    Reset all buttons and textbox\n",
    "\n",
    "    In case, we are at current session with some existing jobs, \n",
    "    then we need to render these jobs.\n",
    "\n",
    "    \"\"\"\n",
    "    job_name_udt = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    _session_id = _param_state['session_id']\n",
    "\n",
    "    # List out existing jobs of this _session_id\n",
    "    existing_jobs = collections.distinct(\n",
    "        \"job_name\",\n",
    "        {\"session_id\": _session_id}\n",
    "    )\n",
    "\n",
    "    job_dropdown_upt = gr.update(\n",
    "        visible=bool(existing_jobs),\n",
    "        value=None,                  # ‚úÖ no selection\n",
    "        choices=existing_jobs,\n",
    "        interactive=True,\n",
    "    )\n",
    "\n",
    "    param_udt = {\n",
    "        'session_id': _session_id,\n",
    "        'job_name': job_name_udt,\n",
    "        'status': None\n",
    "    }\n",
    "\n",
    "    input_section_udt   = gr.update(visible=True)\n",
    "    output_section_udt  = gr.update(visible=False)\n",
    "\n",
    "    inf_sav_txt_udt     = gr.update(value='')\n",
    "    inf_sav_btn_udt     = gr.update(label='Upload SAVs', value=None)\n",
    "    inf_sav_btn_msg_udt = gr.update(value='')\n",
    "    tf_sav_txt_udt      = gr.update(value='')\n",
    "    tf_sav_btn_udt      = gr.update(label='Upload SAVs', value=None)\n",
    "    tf_sav_btn_msg_udt  = gr.update(value='')\n",
    "\n",
    "    str_txt_udt         = gr.update(value='')\n",
    "    str_btn_udt         = gr.update(label='Upload structure', value=None)\n",
    "    str_btn_msg_udt     = gr.update(value='')\n",
    "    job_name_txt_udt    = gr.update(value=job_name_udt)\n",
    "    email_txt_udt       = gr.update('')\n",
    "    submit_status_udt   = gr.update(visible=False)\n",
    "    submit_btn_udt      = gr.update(visible=True, interactive=True)\n",
    "    reset_btn_udt       = gr.update(visible=False)\n",
    "    process_status_udt  = gr.update(value='', visible=False)\n",
    "    return (\n",
    "        param_udt,\n",
    "        job_dropdown_upt,\n",
    "        input_section_udt,\n",
    "        output_section_udt,\n",
    "        inf_sav_txt_udt,\n",
    "        inf_sav_btn_udt,\n",
    "        inf_sav_btn_msg_udt,\n",
    "        tf_sav_txt_udt,\n",
    "        tf_sav_btn_udt,\n",
    "        tf_sav_btn_msg_udt,\n",
    "        str_txt_udt,\n",
    "        str_btn_udt,\n",
    "        str_btn_msg_udt,\n",
    "        job_name_txt_udt,\n",
    "        email_txt_udt,\n",
    "        submit_status_udt,\n",
    "        submit_btn_udt,\n",
    "        reset_btn_udt,\n",
    "        process_status_udt,\n",
    "    )\n",
    "\n",
    "def check_status(_param_state, _submit_status):\n",
    "    \"\"\"\n",
    "    This function is mainly to regulate timer, activating it when job_status is processing.\n",
    "    This activation needs to be search db through time.\n",
    "    \"\"\"\n",
    "    process_status_udt = gr.update()\n",
    "    timer_udt = gr.update()\n",
    "    _submit_status_udt = gr.update()\n",
    "    param_udt = _param_state.copy()\n",
    "\n",
    "    if not _param_state:\n",
    "        return process_status_udt, timer_udt, _submit_status_udt, param_udt\n",
    "\n",
    "    session_id = _param_state.get(\"session_id\", None)\n",
    "    job_name   = _param_state.get(\"job_name\", None)\n",
    "\n",
    "    if not session_id or not job_name:\n",
    "        return process_status_udt, timer_udt, _submit_status_udt, param_udt\n",
    "\n",
    "    # Look for record in db in which it is updated from worker every second\n",
    "    param_udt = collections.find_one(\n",
    "        {\"session_id\": session_id, \"job_name\": job_name}, {\"_id\": 0}\n",
    "    )\n",
    "\n",
    "    if not param_udt:\n",
    "        return process_status_udt, timer_udt, _submit_status_udt, param_udt\n",
    "\n",
    "    _job_status = param_udt.get('status', None)\n",
    "    job_start = param_udt.get(\"job_start\", None)\n",
    "\n",
    "    if _job_status == \"pending\":\n",
    "        process_status_udt = gr.update(value=\"‚è≥ Waiting in queue...\", visible=True)\n",
    "    elif _job_status == \"processing\" and job_start:\n",
    "        elapsed = int(time.time() - job_start)\n",
    "        emoji_frames = [\"‚è≥\", \"üîÑ\", \"üîÅ\", \"üîÉ\"]\n",
    "        icon = emoji_frames[elapsed % len(emoji_frames)]\n",
    "        process_status_udt = gr.update(value=f\"{icon} Model is running... {elapsed} second{'s' if elapsed != 1 else ''} elapsed.\", visible=True)\n",
    "    elif _job_status == \"finished\":\n",
    "        job_end   = param_udt.get(\"job_end\")\n",
    "        runtime = int(job_end - job_start)\n",
    "        process_status_udt = gr.update(visible=False)\n",
    "        msg = _submit_status + f\"\\n‚úÖ Finished in {runtime}s\"\n",
    "        _submit_status_udt = gr.update(value=msg)\n",
    "        timer_udt = gr.update(active=False)\n",
    "\n",
    "    return process_status_udt, timer_udt, _submit_status_udt, param_udt\n",
    "\n",
    "def safe(v):\n",
    "    if v is None or (isinstance(v, float) and math.isnan(v)):\n",
    "        return \"-\"\n",
    "    return v\n",
    "\n",
    "def fmt_prob(v):\n",
    "    if v is None or (isinstance(v, float) and math.isnan(v)):\n",
    "        return \"-\"\n",
    "    return f\"{float(v):.3f}\"\n",
    "\n",
    "def multindex_DataFrame(df):\n",
    "    \n",
    "    df.columns = pd.MultiIndex.from_tuples(\n",
    "        tuple(col.split(\"::\", 1)) if \"::\" in col else (col, \"\")\n",
    "        for col in df.columns\n",
    "    )\n",
    "        \n",
    "    rows = df.to_dict(\"records\")\n",
    "    has_tf = ('TANDEM-DIMPLE', 'probability') in rows[0].keys()\n",
    "\n",
    "    # ---------- build HTML ----------\n",
    "    doc, tag, text = Doc().tagtext()\n",
    "\n",
    "    with tag(\"table\", klass=\"pred-table\"):\n",
    "        # ===== THEAD =====\n",
    "        with tag(\"thead\"):\n",
    "            # --- header row 1 ---\n",
    "            with tag(\"tr\"):\n",
    "                with tag(\"th\", rowspan=\"2\"):\n",
    "                    text(\"Index\")\n",
    "                with tag(\"th\", rowspan=\"2\"):\n",
    "                    text(\"SAV\")\n",
    "                with tag(\"th\", colspan=\"2\"):\n",
    "                    text(\"TANDEM\")\n",
    "                if has_tf:\n",
    "                    with tag(\"th\", colspan=\"2\"):\n",
    "                        text(\"TANDEM-DIMPLE\")\n",
    "\n",
    "            # --- header row 2 ---\n",
    "            with tag(\"tr\"):\n",
    "                with tag(\"th\"):\n",
    "                    text(\"probability\")\n",
    "                with tag(\"th\"):\n",
    "                    text(\"classification\")\n",
    "                if has_tf:\n",
    "                    with tag(\"th\"):\n",
    "                        text(\"probability\")\n",
    "                    with tag(\"th\"):\n",
    "                        text(\"classification\")\n",
    "\n",
    "        # ===== TBODY =====\n",
    "        with tag(\"tbody\"):\n",
    "            for i, row in enumerate(rows):\n",
    "                with tag(\"tr\"):\n",
    "                    with tag(\"td\"):\n",
    "                        text(i)\n",
    "                    with tag(\"td\"):\n",
    "                        text(safe(row.get(('SAV', 'SAV'))))\n",
    "\n",
    "                    # TANDEM\n",
    "                    with tag(\"td\"):\n",
    "                        text(fmt_prob(row.get(('TANDEM', 'probability'))))\n",
    "                    with tag(\"td\"):\n",
    "                        text(safe(row.get(('TANDEM', 'classification'))))\n",
    "\n",
    "                    # TANDEM-DIMPLE (optional)\n",
    "                    if has_tf:\n",
    "                        with tag(\"td\"):\n",
    "                            text(fmt_prob(row.get(('TANDEM-DIMPLE', 'probability'))))\n",
    "                        with tag(\"td\"):\n",
    "                            text(safe(row.get(('TANDEM-DIMPLE', 'classification'))))\n",
    "\n",
    "    # ---------- final HTML ----------\n",
    "    html_str = doc.getvalue()\n",
    "    return html_str\n",
    "\n",
    "def render_output(_param_state, folder):\n",
    "    \"\"\n",
    "    _job_status = _param_state.get('status', None)\n",
    "    output_section_udt = gr.update(visible=False)\n",
    "    pred_table_udt = gr.update(visible=False)\n",
    "    result_zip_udt = gr.update(visible=False)\n",
    "    image_selector_udt = gr.update(visible=False)\n",
    "    image_viewer_udt = gr.update(visible=False)\n",
    "\n",
    "    if _job_status != \"finished\":\n",
    "        return output_section_udt, pred_table_udt, result_zip_udt, image_selector_udt, image_viewer_udt\n",
    "\n",
    "    output_section_udt = gr.update(visible=True)\n",
    "    session_id = _param_state[\"session_id\"]\n",
    "    job_name   = _param_state[\"job_name\"]\n",
    "    job_folder = os.path.join(folder, session_id, job_name) \n",
    "    pred_file = os.path.join(job_folder, \"predictions.csv\")\n",
    "    df_pred   = pd.read_csv(pred_file)\n",
    "    pred_table_udt = gr.update(value=multindex_DataFrame(df_pred), visible=True)\n",
    "    \n",
    "    zip_path = zip_folder(job_folder)\n",
    "    result_zip_udt = gr.update(value=zip_path, interactive=True, visible=bool(zip_path))\n",
    "\n",
    "    tandem_shap = os.path.join(job_folder, 'tandem_shap') \n",
    "    list_images = os.listdir(tandem_shap)\n",
    "\n",
    "    image_selector_udt = gr.update(\n",
    "        choices=list_images,\n",
    "        value=list_images[0] if list_images else None,\n",
    "        visible=bool(list_images),\n",
    "    )\n",
    "\n",
    "    image_viewer_udt = gr.update(\n",
    "        value=os.path.join(tandem_shap, list_images[0]) if list_images else None,\n",
    "        visible=bool(list_images),\n",
    "    )\n",
    "\n",
    "    return output_section_udt, pred_table_udt, result_zip_udt, image_selector_udt, image_viewer_udt\n",
    "\n",
    "def on_auto_fill(mode, auto_fill):\n",
    "    if not auto_fill:\n",
    "        sav_txt = gr.update(value=\"\")\n",
    "        str_file = gr.update()\n",
    "        return sav_txt, str_file\n",
    "    \n",
    "    if mode == \"Inferencing\":\n",
    "        inf_test_SAVs = (\n",
    "            f\"O00189 R271H\\n\"\n",
    "            f\"O00194 P138L\\n\"\n",
    "            f\"O00194 A92T\\n\"\n",
    "            f\"O00204 V240I\\n\"\n",
    "            f\"O00204 L51S\\n\"\n",
    "            f\"O00206 T175A\\n\"\n",
    "            f\"O00206 Q188R\\n\"\n",
    "            f\"O00206 C246S\\n\"\n",
    "            f\"O00206 E287D\\n\"\n",
    "            f\"O00206 E287G\\n\"\n",
    "            f\"O00206 C306W\\n\"\n",
    "        )\n",
    "        sav_txt = gr.update(value=inf_test_SAVs)\n",
    "        str_file = gr.update()\n",
    "    elif mode == \"Transfer Learning\":\n",
    "        tf_test_SAVs = (\n",
    "            f\"P29033 Y217D 0\\n\"\n",
    "            f\"P29033 I215M 0\\n\"\n",
    "            f\"P29033 L214V 0\\n\"\n",
    "            f\"P29033 L210V 0\\n\"\n",
    "            f\"P29033 I203T 0\\n\"\n",
    "            f\"P29033 A197T 0\\n\"\n",
    "            f\"P29033 N170K 0\\n\"\n",
    "            f\"P29033 N170S 0\\n\"\n",
    "            f\"P29033 K168R 0\\n\"\n",
    "            f\"P29033 V156I 0\\n\"\n",
    "            f\"P29033 V153I 0\\n\"\n",
    "            f\"P29033 R127H 0\\n\"\n",
    "            f\"P29033 T123N 0\\n\"\n",
    "            f\"P29033 I121V 0\\n\"\n",
    "            f\"P29033 F115V 0\\n\"\n",
    "            f\"P29033 E114G 0\\n\"\n",
    "            f\"P29033 I111T 0\\n\"\n",
    "            f\"P29033 I107L 0\\n\"\n",
    "            f\"P29033 H100Q 0\\n\"\n",
    "            f\"P29033 F83L 0\\n\"\n",
    "            f\"P29033 V27I 0\\n\"\n",
    "            f\"P29033 H16Y 0\\n\"\n",
    "            f\"P29033 G4V 0\\n\"\n",
    "            f\"P29033 G4D 0\\n\"\n",
    "            f\"P29033 R165W 0\\n\"\n",
    "            f\"P29033 M34T 1\\n\"\n",
    "            f\"P29033 V37I 1\\n\"\n",
    "            f\"P29033 W44C 1\\n\"\n",
    "            f\"P29033 W44S 1\\n\"\n",
    "            f\"P29033 D50N 1\\n\"\n",
    "            f\"P29033 G59A 1\\n\"\n",
    "            f\"P29033 R75Q 1\\n\"\n",
    "            f\"P29033 R75W 1\\n\"\n",
    "            f\"P29033 V84L 1\\n\"\n",
    "            f\"P29033 L90P 1\\n\"\n",
    "            f\"P29033 V95M 1\\n\"\n",
    "            f\"P29033 R143W 1\\n\"\n",
    "            f\"P29033 R143Q 1\\n\"\n",
    "            f\"P29033 F161S 1\\n\"\n",
    "            f\"P29033 M163T 1\\n\"\n",
    "            f\"P29033 D179N 1\\n\"\n",
    "            f\"P29033 R184Q 1\\n\"\n",
    "            f\"P29033 M195T 1\\n\"\n",
    "            f\"P29033 A197S 1\\n\"\n",
    "            f\"P29033 C202F 1\\n\"\n",
    "            f\"P29033 L205V 1\\n\"\n",
    "            f\"P29033 N206S 1\\n\"\n",
    "        )\n",
    "        sav_txt = gr.update(value=tf_test_SAVs)\n",
    "        str_file = os.path.join(root, 'gradio_app/test/8qa2_opm_25Apr03.pdb')\n",
    "    else:\n",
    "        raise KeyError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "    return sav_txt, str_file\n",
    "\n",
    "def on_mode(mode):\n",
    "    inf_mode = gr.update(visible=(mode == \"Inferencing\"))\n",
    "    tf_mode = gr.update(visible=(mode == \"Transfer Learning\"))\n",
    "    return (inf_mode, tf_mode)\n",
    "\n",
    "def on_structure(checked: bool):\n",
    "    structure_section_udt = gr.update(visible=checked)\n",
    "    return structure_section_udt\n",
    "\n",
    "def tandem_input(time_interval=1):\n",
    "    \"\"\"\n",
    "    Next try: DeletedFileData, Error, ParamViewer\n",
    "    https://www.gradio.app/docs/gradio/deletedfiledata\n",
    "    https://www.gradio.app/docs/gradio/error\n",
    "    https://www.gradio.app/docs/gradio/paramviewer\n",
    "\n",
    "    \"\"\"\n",
    "    with gr.Group(visible=False) as input_section:\n",
    "\n",
    "        ####### Start\n",
    "        mode = gr.Radio([\"Inferencing\", \"Transfer Learning\"], value=\"Inferencing\", label=\"Mode of Actions\")\n",
    "        # Inferencing input mode\n",
    "        with gr.Group(visible=True) as inf_section:\n",
    "            with gr.Row():\n",
    "                label = \"Paste single amino acid variants (leave empty to run the test case)\"\n",
    "                placeholder=\"O14508 S52N\\nP29033 Y217D\\n...\"\n",
    "                inf_sav_txt = gr.Textbox(value='', interactive=True, max_lines=5, lines=4, elem_id=\"sav-txt\", label=label, placeholder=placeholder, scale=6)\n",
    "                inf_sav_btn = gr.UploadButton(label=\"Upload SAVs\", file_count=\"single\", file_types=[\".txt\"], elem_id=\"sav-btn\", scale=3)\n",
    "                inf_sav_file = gr.File(visible=False, file_types=[\".txt\"], height=145, scale=3)\n",
    "            \n",
    "            inf_auto_fill = gr.Checkbox(label=\"Do you want to load the test input?\", interactive=True)\n",
    "            choices = [\"TANDEM\", \"TANDEM-DIMPLE for GJB2\", \"TANDEM-DIMPLE for RYR1\"]\n",
    "            model_dropdown = gr.Dropdown(value=\"TANDEM\", label=\"Model\", choices=choices, interactive=True, filterable=False)\n",
    "\n",
    "        # Transfer Learning input mode\n",
    "        with gr.Group(visible=False) as tf_section:\n",
    "            with gr.Row():\n",
    "                label=\"Paste single amino acid variants and the corresponding labels (leave empty to run the test case)\"\n",
    "                placeholder=\"O14508 S52N 1\\nP29033 Y217D 0\\n...\"\n",
    "                tf_sav_txt = gr.Textbox(value='', interactive=True, max_lines=5, lines=4, elem_id=\"sav-txt\", label=label, placeholder=placeholder, scale=6)\n",
    "                tf_sav_btn = gr.UploadButton(label=\"Upload SAVs\", file_count=\"single\", file_types=[\".txt\"], elem_id=\"sav-btn\", scale=3)\n",
    "                tf_sav_file = gr.File(visible=False, file_types=[\".txt\"], height=145, scale=3)\n",
    "            tf_auto_fill = gr.Checkbox(label=\"Do you want to load the test input?\", interactive=True)\n",
    "\n",
    "        # Assign/Upload your structure\n",
    "        str_check = gr.Checkbox(value=False, label=\"Provide PDB/AF2 ID or upload coordinate file\", interactive=True)\n",
    "        with gr.Row(visible=False) as structure_section:\n",
    "            str_txt = gr.Textbox(value=None, label=\"Structure\", placeholder=\"PDB ID (e.g., 1GOD) or AF2 ID (e.g., 014508)\", interactive=True, show_label=False, scale=6)\n",
    "            str_btn = gr.UploadButton(\"Upload file\", file_count=\"single\", elem_id=\"sav-btn\", file_types=[\".cif\", \".pdb\"], scale=3)\n",
    "            str_file = gr.File(visible=False, scale=3, height=145)\n",
    "        str_check.change(on_structure, str_check, [structure_section])\n",
    "\n",
    "        # General info\n",
    "        job_name = datetime.now(time_zone).strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        job_name_txt = gr.Textbox(value=job_name, label=\"Job name\", placeholder=\"Enter job name\", interactive=True)\n",
    "        email_txt = gr.Textbox(value=None, label=\"Email (Optional)\", placeholder=\"Enter your email\", interactive=True, visible=False, type='email')\n",
    "\n",
    "    with gr.Group(visible=False) as submit_section:\n",
    "        # Submit job\n",
    "        submit_status = gr.Textbox(label=\"Submission Status\", visible=False, lines=10, interactive=False, elem_id=\"submit-status\")\n",
    "        process_status = gr.Textbox(label=\"Processing Status\", visible=False, lines=1, interactive=False, elem_id=\"process-status\")\n",
    "        submit_btn = gr.Button(\"Submit\")\n",
    "        reset_btn = gr.Button(\"New job\", visible=False)\n",
    "    \n",
    "    timer = gr.Timer(value=time_interval, active=False) # Timer to check result\n",
    "\n",
    "    # Fill test case\n",
    "    inf_auto_fill.change(fn=on_auto_fill, inputs=[mode, inf_auto_fill], outputs=[inf_sav_txt, str_file])\n",
    "    tf_auto_fill.change(fn=on_auto_fill, inputs=[mode, tf_auto_fill], outputs=[tf_sav_txt, str_file])\n",
    "\n",
    "    # Select mode (1) Inferencing or (2) Transfer Learning\n",
    "    mode.change(fn=on_mode, inputs=mode, outputs=[inf_section, tf_section])\n",
    "\n",
    "    # Upload\n",
    "    inf_sav_btn.upload(fn=upload_file, inputs=[inf_sav_btn], outputs=[inf_sav_btn, inf_sav_file])\n",
    "    tf_sav_btn.upload(fn=upload_file, inputs=[tf_sav_btn], outputs=[tf_sav_btn, tf_sav_file])\n",
    "    str_btn.upload(fn=upload_file, inputs=[str_btn], outputs=[str_btn, str_file])\n",
    "\n",
    "    # Delete file\n",
    "    inf_sav_file.delete(fn=on_delete_file, inputs=[inf_sav_file], outputs=[inf_sav_btn, inf_sav_file])\n",
    "    tf_sav_file.delete(fn=on_delete_file, inputs=[tf_sav_file], outputs=[tf_sav_btn, tf_sav_file])\n",
    "    str_file.delete(fn=on_delete_file, inputs=[str_file], outputs=[str_btn, str_file])\n",
    "\n",
    "    return (\n",
    "        input_section,\n",
    "        mode,\n",
    "        inf_section,\n",
    "        inf_sav_txt,\n",
    "        inf_sav_file,\n",
    "        model_dropdown,\n",
    "        \n",
    "        tf_section,\n",
    "        tf_sav_txt,\n",
    "        tf_sav_file,\n",
    "\n",
    "        str_txt,\n",
    "        str_file,\n",
    "\n",
    "        job_name_txt,\n",
    "        email_txt,\n",
    "\n",
    "        submit_section,\n",
    "        submit_status,\n",
    "        process_status,\n",
    "        submit_btn,\n",
    "        reset_btn,\n",
    "\n",
    "        timer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d4f0b0",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d31fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.web_interface import session, tandem_output\n",
    "# from src.web_interface import tandem_output, tandem_input\n",
    "from src.update_session import then_session\n",
    "from src.update_input import update_input_param\n",
    "from src.job import on_submit \n",
    "from src.update_output import on_select_image\n",
    "\n",
    "def right_column(param_state: gr.State, jobs_folder_state: gr.State):\n",
    "    \n",
    "    # Session UI\n",
    "    (\n",
    "        session_id, \n",
    "        session_btn, \n",
    "        session_status, \n",
    "        job_dropdown\n",
    "\n",
    "    ) = session()\n",
    "    \n",
    "    # Input UI\n",
    "    (\n",
    "        input_section,\n",
    "        mode,\n",
    "        inf_section,\n",
    "        inf_sav_txt,\n",
    "        inf_sav_file,\n",
    "        model_dropdown,\n",
    "        \n",
    "        tf_section,\n",
    "        tf_sav_txt,\n",
    "        tf_sav_file,\n",
    "\n",
    "        str_txt,\n",
    "        str_file,\n",
    "\n",
    "        job_name_txt,\n",
    "        email_txt,\n",
    "\n",
    "        submit_section,\n",
    "        submit_status,\n",
    "        process_status,\n",
    "        submit_btn,\n",
    "        reset_btn,\n",
    "\n",
    "        timer,\n",
    "\n",
    "    ) = tandem_input()\n",
    "\n",
    "    # Result UI\n",
    "    (\n",
    "        output_section,\n",
    "        pred_table,\n",
    "        image_selector,\n",
    "        image_viewer,\n",
    "        result_zip\n",
    "\n",
    "    ) = tandem_output()\n",
    "\n",
    "    ################-------------Simulate session event----------------################\n",
    "    # Generate/resume session\n",
    "    session_click_event = session_btn.click(\n",
    "        fn=on_session,\n",
    "        inputs=[session_id, param_state],\n",
    "        outputs=[session_id, session_status, job_dropdown, param_state, model_dropdown]\n",
    "    )\n",
    "    session_submit_event = session_id.submit(\n",
    "        fn=on_session,\n",
    "        inputs=[session_id, param_state],\n",
    "        outputs=[session_id, session_status, job_dropdown, param_state, model_dropdown]\n",
    "    )\n",
    "\n",
    "    # Visualize input section\n",
    "    session_event = [session_click_event, session_submit_event]\n",
    "    for i, event in enumerate(session_event):\n",
    "        session_event[i] = event.then(\n",
    "            fn=then_session,\n",
    "            inputs=[param_state, jobs_folder_state, submit_status],\n",
    "            outputs=[\n",
    "                input_section,\n",
    "                submit_section,\n",
    "                output_section,\n",
    "                pred_table,\n",
    "                result_zip,\n",
    "                image_selector,\n",
    "                image_viewer,\n",
    "                submit_status,\n",
    "                submit_btn,\n",
    "                reset_btn\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    ###############---input_section following job selection--------################\n",
    "    job_dropdown.select(\n",
    "        fn=on_job, \n",
    "        inputs=[job_dropdown, param_state, jobs_folder_state], \n",
    "        outputs=[\n",
    "            input_section,\n",
    "            submit_section,\n",
    "            output_section,\n",
    "            process_status,\n",
    "            pred_table,\n",
    "            result_zip,\n",
    "            image_selector,\n",
    "            image_viewer,\n",
    "            submit_status,\n",
    "            submit_btn,\n",
    "            reset_btn,\n",
    "            param_state,\n",
    "            timer,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ###############---input_section following job selection--------################\n",
    "    submit_event = submit_btn.click(\n",
    "        fn=on_submit, \n",
    "        inputs=[mode, inf_sav_txt, inf_sav_file, tf_sav_txt, tf_sav_file, str_file], \n",
    "        outputs=[mode, inf_sav_txt, inf_sav_file, tf_sav_txt, tf_sav_file, str_file, submit_status,  submit_btn]\n",
    "    ).then( \n",
    "        # Start timer after submission\n",
    "        fn=lambda: gr.update(active=True),\n",
    "        inputs=[],\n",
    "        outputs=timer\n",
    "    )\n",
    "\n",
    "    reset_event = reset_btn.click(\n",
    "        # Stop timer after reset\n",
    "        fn=lambda: gr.update(active=False),\n",
    "        inputs=[],\n",
    "        outputs=timer\n",
    "    ).then(\n",
    "        fn=on_reset, inputs=[param_state], \n",
    "        outputs=[\n",
    "            param_state,\n",
    "            job_dropdown,\n",
    "            input_section,\n",
    "            output_section,\n",
    "            inf_sav_txt,\n",
    "            inf_sav_file,\n",
    "            tf_sav_txt,\n",
    "            tf_sav_file,\n",
    "            str_txt,\n",
    "            str_file,\n",
    "            job_name_txt,\n",
    "            email_txt,\n",
    "            submit_status,\n",
    "            submit_btn,\n",
    "            reset_btn,\n",
    "            process_status,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    submit_event = submit_event.then(\n",
    "        fn=update_input_param,\n",
    "        inputs=[\n",
    "            mode,\n",
    "            inf_sav_txt,\n",
    "            inf_sav_file,\n",
    "            model_dropdown,\n",
    "            tf_sav_txt,\n",
    "            tf_sav_file,\n",
    "            str_txt,\n",
    "            str_file,\n",
    "            job_name_txt,\n",
    "            email_txt,\n",
    "            param_state,\n",
    "            submit_status,\n",
    "        ],\n",
    "        outputs=[param_state, input_section, submit_status, submit_btn, reset_btn, timer],\n",
    "    )\n",
    "\n",
    "    ###############--------Submission event, send job---------################\n",
    "    submit_event = submit_event.then(\n",
    "            fn=send_job,\n",
    "            inputs=[param_state, jobs_folder_state],\n",
    "            outputs=param_state,\n",
    "        )\n",
    "\n",
    "    # ###############--------Timer, report job status---------################\n",
    "    # Check job status and update submit_status\n",
    "    # timer = gr.Timer(value=1, active=False) # Timer to check result\n",
    "    timer.tick(\n",
    "        fn=check_status,\n",
    "        inputs=[param_state, submit_status],\n",
    "        outputs=[process_status, timer, submit_status, param_state]\n",
    "    ).then( \n",
    "    # Visualize results based on param_state['status']\n",
    "        fn=render_output,\n",
    "        inputs=[param_state, jobs_folder_state],\n",
    "        outputs=[output_section, pred_table, result_zip, image_selector, image_viewer]\n",
    "    )\n",
    "    \n",
    "    image_selector.change(\n",
    "        fn=on_select_image,\n",
    "        inputs=[image_selector, jobs_folder_state, param_state],\n",
    "        outputs=image_viewer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60c56b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7890\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7890/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%blocks --share\n",
    "# LOGGER.start('website.log')\n",
    "\n",
    "with gr.Blocks(css=custom_css) as demo:\n",
    "    param_state = gr.State({})\n",
    "    jobs_folder_state = gr.State(jobs_folder)\n",
    "    right_column(param_state, jobs_folder_state)\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(server_port=7890, allowed_paths=[\"../tandem/jobs\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fcac7f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7890\n"
     ]
    }
   ],
   "source": [
    "# LOGGER.close('website.log')\n",
    "# P29033 Y217D\n",
    "# P29033 Y217D\n",
    "# http://140.114.97.207:7863\n",
    "# lN0UGkWMRm\n",
    "# FqqMduC6Tw\n",
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tandem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
